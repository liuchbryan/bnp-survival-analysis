source('censored_MCMC.R')
require(parmsurvfit)
source('censored_MCMC.R')
check_arguments <- function(t, delta){
if (length(t) != length(delta)){
stop("Lengths of delta and t should match")
}
if (sum(!(delta == 1 | delta ==0)) != 0){
stop("delta should be a binary vector")
}
}
a <- c(0,1)
rm(a)
a
?fit_data
data('rearrest')
fit_data(rearrest, "lnorm", time = "months")
rearrest
str(rearrest)
mean(log(rearrest$months))
fit_data(rearrest, "lnorm", time = "months")
sd(log(rearrest$months))
require(parmsurvfit)
source('censored_MCMC.R')
source('k_samples_testing.R')
check_arguments <- function(t, delta){
if (length(t) != length(delta)){
stop("Lengths of delta and t should match")
}
if (sum(!(delta == 1 | delta ==0)) != 0){
stop("delta should be a binary vector")
}
}
sample(c(1,2,3,4,5,6,7,8))
censored_permutation_test <- function(t1, t2, delta1, delta2, N_permutations){
# simple check
check_arguments(t1, delta1)
check_arguments(t2, delta2)
# null hypothsis dataset
J <- ceiling(log(t1+t2, base = 2))
t0 <- c(t1, t2)
delta0 <- c(delta1, delta2)
L1 <- length(t1)
L0 <- length(t0)
# compute \bar{p_i} for censored groups and datasets
# bar_p0 <- censored_MH(t = t0, delta = delta0, J = J)$Ep # Do we actually need this??
bar_p1 <- censored_MH(t = t1, delta = delta1, J = J)$Ep
bar_p2 <- censored_MH(t = t2, delta = delta2, J = J)$Ep
statistic_numerator <- bar_p1 * bar_p2
numerator_distribution <- rep(0, N_permutations)
# now shuffle
for (i_perm in 1:N_permutations){
# permute and divide in new groups with same sizes as t1, t2
new_groups_indices <- sample(1:L0)
group1_indices <- new_groups_indices[1:L1]
group2_indices <- new_groups_indices[(L1+1):L0]
new_t1 <- t0[group1_indices]
new_t2 <- t0[group2_indices]
new_delta1 <-delta0[group1_indices]
new_delta2 <-delta0[group2_indices]
# compute numerator of stat for this partition
new_bar_p1 <- censored_MH(t = new_t1, delta = new_delta1, J = J)$Ep
new_bar_p2 <- censored_MH(t = new_t2, delta = new_delta2, J = J)$Ep
# store statistic numerator
numerator_distribution[i_perm] <- new_bar_p1 * new_bar_p2
}
p_value <- mean(statistic_numerator < numerator_distribution )
return(list(p_value = p_value, statistic_numerator = statistic_numerator))
}
t1 <- rexp(15)
t2 <- rexp(15)
x1 <- rexp(15)
x2 <- rexp(15)
x1
?rexp
mean(rexp(1000000))
x1 <- rexp(15)
x2 <- rexp(15)
x1
x2
x1 <- rexp(15)
x2 <- rexp(15)
c1 <- runif(15, min = 0, max = .5)
c2 <- runif(15, min = 0, max = .5)
min(c1, c1)
?sapply
?mapply
mapply(min, x1, c1)
x1
c1
mapply(min, x1, c1) == c1
x1 <- rexp(15)
x2 <- rexp(15)
c1 <- runif(15, min = 0, max = 1.5)
c2 <- runif(15, min = 0, max = 1.5)
t1 <- min(x1, c1)
t1 < c1
x1 <- rexp(15)
x2 <- rexp(15)
c1 <- runif(15, min = 0, max = 1)
c2 <- runif(15, min = 0, max = 1)
t1 <- min(x1, c1)
t1 < c1
c1 <- runif(15, min = 0, max = .75)
t1 <- min(x1, c1)
t1 < c1
c1 <- runif(15, min = 0, max = .4)
x1 <- rexp(100000)
c1 <- runif(100000, min = 0.2, max = )
x1 <- rexp(100000)
c1 <- runif(100000, min = 0.2, max = )
t1 <- min(x1, c1)
t1 < mean(t1)
x1 <- rexp(100000)
c1 <- runif(100000, min = 0, max = 1)
t1 <- min(x1, c1)
t1 < mean(t1)
t1
t1 <- mapply(min,x1, c1)
t1 < mean(t1)
t1 < mean(t1)
x1 <- rexp(100000)
c1 <- runif(100000, min = 0, max = 1)
t1 <- mapply(min,x1, c1)
# proportion of censored
mean(t1 == c1)
x1 <- rexp(100000)
c1 <- runif(100000, min = 0, max = .5)
t1 <- mapply(min,x1, c1)
# proportion of censored
mean(t1 == c1)
x1 <- rexp(100000)
c1 <- runif(100000, min = 0, max = 2)
t1 <- mapply(min,x1, c1)
# proportion of censored
mean(t1 == c1)
x1 <- rexp(100000)
c1 <- runif(100000, min = 0, max = 3)
t1 <- mapply(min,x1, c1)
# proportion of censored
mean(t1 == c1)
x1 <- rexp(100000)
c1 <- runif(100000, min = 1, max = 3)
t1 <- mapply(min,x1, c1)
# proportion of censored
mean(t1 == c1)
x1 <- rexp(100000)
c1 <- runif(100000, min = 1, max = 2)
t1 <- mapply(min,x1, c1)
# proportion of censored
mean(t1 == c1)
x1 <- rexp(50)
c1 <- runif(50, min = 1, max = 2)
t1 <- mapply(min,x1, c1)
x2 <- rexp(50)
c2 <- runif(50, min = 1, max = 2)
t2 <- mapply(min,x2, c2)
delta1 <- as.numeric( t1 == c1 )
x1 <- rexp(50)
c1 <- runif(50, min = 1, max = 2)
t1 <- mapply(min,x1, c1)
delta1 <- as.numeric( x1 < c1 )
x2 <- rexp(50)
c2 <- runif(50, min = 1, max = 2)
t2 <- mapply(min,x2, c2)
delta2 <- as.numeric( x2 < c2 )
censored_permutation_test <- function(t1, t2, delta1, delta2, N_permutations){
# simple check
check_arguments(t1, delta1)
check_arguments(t2, delta2)
# null hypothsis dataset
J <- ceiling(log(t1+t2, base = 2))
t0 <- c(t1, t2)
delta0 <- c(delta1, delta2)
L1 <- length(t1)
L0 <- length(t0)
# compute \bar{p_i} for censored groups and datasets
# bar_p0 <- censored_MH(t = t0, delta = delta0, J = J)$Ep # Do we actually need this??
bar_p1 <- censored_MH(t = t1, delta = delta1, J = J)$Ep
bar_p2 <- censored_MH(t = t2, delta = delta2, J = J)$Ep
statistic_numerator <- bar_p1 * bar_p2
numerator_distribution <- rep(0, N_permutations)
# now shuffle
for (i_perm in 1:N_permutations){
print0('Permutation Number: ', i_perm, '/r')
# permute and divide in new groups with same sizes as t1, t2
new_groups_indices <- sample(1:L0)
group1_indices <- new_groups_indices[1:L1]
group2_indices <- new_groups_indices[(L1+1):L0]
new_t1 <- t0[group1_indices]
new_t2 <- t0[group2_indices]
new_delta1 <-delta0[group1_indices]
new_delta2 <-delta0[group2_indices]
# compute numerator of stat for this partition
new_bar_p1 <- censored_MH(t = new_t1, delta = new_delta1, J = J)$Ep
new_bar_p2 <- censored_MH(t = new_t2, delta = new_delta2, J = J)$Ep
# store statistic numerator
numerator_distribution[i_perm] <- new_bar_p1 * new_bar_p2
}
p_value <- mean(statistic_numerator < numerator_distribution )
return(list(p_value = p_value, statistic_numerator = statistic_numerator))
}
censored_permutation_test(t1 = t1, t2 = t2, delta1 = delta1, delta2 = delta2, 10)
censored_permutation_test <- function(t1, t2, delta1, delta2, N_permutations){
# simple check
check_arguments(t1, delta1)
check_arguments(t2, delta2)
# null hypothsis dataset
t0 <- c(t1, t2)
delta0 <- c(delta1, delta2)
L1 <- length(t1)
L0 <- length(t0)
J <- ceiling( log(L0, base = 2) )
# compute \bar{p_i} for censored groups and datasets
# bar_p0 <- censored_MH(t = t0, delta = delta0, J = J)$Ep # Do we actually need this??
bar_p1 <- censored_MH(t = t1, delta = delta1, J = J)$Ep
bar_p2 <- censored_MH(t = t2, delta = delta2, J = J)$Ep
statistic_numerator <- bar_p1 * bar_p2
numerator_distribution <- rep(0, N_permutations)
# now shuffle
for (i_perm in 1:N_permutations){
print0('Permutation Number: ', i_perm, '/r')
# permute and divide in new groups with same sizes as t1, t2
new_groups_indices <- sample(1:L0)
group1_indices <- new_groups_indices[1:L1]
group2_indices <- new_groups_indices[(L1+1):L0]
new_t1 <- t0[group1_indices]
new_t2 <- t0[group2_indices]
new_delta1 <-delta0[group1_indices]
new_delta2 <-delta0[group2_indices]
# compute numerator of stat for this partition
new_bar_p1 <- censored_MH(t = new_t1, delta = new_delta1, J = J)$Ep
new_bar_p2 <- censored_MH(t = new_t2, delta = new_delta2, J = J)$Ep
# store statistic numerator
numerator_distribution[i_perm] <- new_bar_p1 * new_bar_p2
}
p_value <- mean(statistic_numerator < numerator_distribution )
return(list(p_value = p_value, statistic_numerator = statistic_numerator))
}
x1 <- rexp(50)
c1 <- runif(50, min = 1, max = 2)
t1 <- mapply(min,x1, c1)
delta1 <- as.numeric( x1 < c1 )
x2 <- rexp(50)
c2 <- runif(50, min = 1, max = 2)
t2 <- mapply(min,x2, c2)
delta2 <- as.numeric( x2 < c2 )
censored_permutation_test(t1 = t1, t2 = t2, delta1 = delta1, delta2 = delta2, 10)
?print0
?print
print('aaaa', 1, '\r')
censored_permutation_test <- function(t1, t2, delta1, delta2, N_permutations){
# simple check
check_arguments(t1, delta1)
check_arguments(t2, delta2)
# null hypothsis dataset
t0 <- c(t1, t2)
delta0 <- c(delta1, delta2)
L1 <- length(t1)
L0 <- length(t0)
J <- ceiling( log(L0, base = 2) )
# compute \bar{p_i} for censored groups and datasets
# bar_p0 <- censored_MH(t = t0, delta = delta0, J = J)$Ep # Do we actually need this??
bar_p1 <- censored_MH(t = t1, delta = delta1, J = J)$Ep
bar_p2 <- censored_MH(t = t2, delta = delta2, J = J)$Ep
statistic_numerator <- bar_p1 * bar_p2
numerator_distribution <- rep(0, N_permutations)
# now shuffle
for (i_perm in 1:N_permutations){
print(paste0('Permutation Number: ', i_perm, '/r'))
# permute and divide in new groups with same sizes as t1, t2
new_groups_indices <- sample(1:L0)
group1_indices <- new_groups_indices[1:L1]
group2_indices <- new_groups_indices[(L1+1):L0]
new_t1 <- t0[group1_indices]
new_t2 <- t0[group2_indices]
new_delta1 <-delta0[group1_indices]
new_delta2 <-delta0[group2_indices]
# compute numerator of stat for this partition
new_bar_p1 <- censored_MH(t = new_t1, delta = new_delta1, J = J)$Ep
new_bar_p2 <- censored_MH(t = new_t2, delta = new_delta2, J = J)$Ep
# store statistic numerator
numerator_distribution[i_perm] <- new_bar_p1 * new_bar_p2
}
p_value <- mean(statistic_numerator < numerator_distribution )
return(list(p_value = p_value, statistic_numerator = statistic_numerator))
}
censored_permutation_test(t1 = t1, t2 = t2, delta1 = delta1, delta2 = delta2, 10)
censored_permutation_test(t1 = t1, t2 = t2, delta1 = delta1, delta2 = delta2, 100)
x1 <- rexp(50)
c1 <- runif(50, min = 1, max = 2)
t1 <- mapply(min,x1, c1)
delta1 <- as.numeric( x1 < c1 )
x2 <- rexp(50, rate = 40)
c2 <- runif(50, min = 1, max = 2)
t2 <- mapply(min,x2, c2)
delta2 <- as.numeric( x2 < c2 )
censored_permutation_test(t1 = t1, t2 = t2, delta1 = delta1, delta2 = delta2, 10)
t1
t2
delta1
delta2
compute_s0(x2, x2, J = 6, mu_hat = 1, sd_hat = 1)
censored_MH <- function(t, delta, J, B = 100, M = 200, V = 1.5){
# if no censored data in (t,delta)
# check lengths
N <- length(t)
if (length(delta) != N){stop("Lengths of delta and t should match")}
# Transform to log scale and define bounds for each observation
censored_indices <- which(delta == 0)
censored_length <- length(censored_indices)
x <- log(t)
# compute MLEs
# do i need to do it here?
data <- data.frame(time = t, censor = delta)
fit <- parmsurvfit::fit_data(data, dist = 'lnorm')
mu_hat <- fit$estimate[1]
sd_hat <- fit$estimate[2]
rm(data)
# sample latent log censored deaths
x <- sample_censored(x, censored_indices, mu_hat, sd_hat)
# initialise stuff
c <- 1
SUM <- 0
# Compute n(J, k) matrix of 'bin' counts of the 'normal' partition
n <- list()
n[[J]] <- rep(0, 2^J)
for (i in 1:N){
bin <- ceiling(2^J*pnorm(x[i], mean = mu_hat, sd = sd_hat))
n[[J]][bin] <- n[[J]][bin] + 1
}
if (J > 1){
for (j in (J-1):1){
n[[j]] <- rep(0, 2^j)
n[[j]] <- n[[j+1]] + head(c(0, n[[j+1]]),-1)
n[[j]] <- n[[j]][seq_along(n[[j]])%%2 == 0]
}
}
# Helper function
# MH
log_qx <- algo1(J = J, c = c, x = x, mu = mu_hat, sigma = sd_hat)
for( iter in 1:(B+M)){
# STEP 1 # -------------------------------------------
if(censored_length > 0){
x_prop <- sample_censored(x, censored_indices, mu_hat, sd_hat)
# pwise comparison x_prob[censored_indices] vs x[censored_indices]
k <- ceiling(2^J*pnorm(x, mean = mu_hat, sd = sd_hat))[censored_indices]
k_prop <- ceiling(2^J*pnorm(x_prop, mean = mu_hat, sd = sd_hat))[censored_indices]
s0 <- mapply(compute_s0, k, k_prop,
MoreArgs = list(J = J,
mu_hat = mu_hat,
sd_hat = sd_hat))
alpha <- rep(0, censored_length)
alpha[which(s0 != J)] <- log(c*J^2 + n[[J]][k_prop]) - log(c*J^2 + n[[J]][k])
# What if s0 = J-1  V
# What if s0 = J X we want the for loop not to run
for (s in min(s0+1, J-1):(J-1)){
# might need to make sure min(s0) < J-1 but not sure
indices <- which(s0 < s)
alpha[indices] <- (alpha[indices] +
log(c*s^2 + n[[s]][ ceiling(2^(s-J)*k_prop[indices])]) -
log(c*s^2 + n[[s]][ ceiling(2^(s-J)*k[indices])]) +
log(2*c*(s+1)^2 + n[[s]][ ceiling(2^(s-J)*k[indices])] ) -
log(2*c*(s+1)^2 + n[[s]][ ceiling(2^(s-J)*k_prop[indices])])
)
}
#(e)
u <- runif(censored_length)
changed_indices <- which(u < exp(alpha))
# for all u
# x has dimension N
# u has dimension censored_length -> ch_indices is referring to 'censored dataset' indices
x[censored_indices[changed_indices]] <- x_prop[censored_indices[changed_indices]]
# s0 = J
#bool <- ( min(s0) == J) -> might implement above
for (s in min(s0+1, J):J){
# if (bool){break}
indices <- which(s0 < s)
n[[s]][ceiling(2^(s-J)*k_prop[indices])] <- n[[s]][ceiling(2^(s-J)*k_prop[indices])] + 1
n[[s]][2^(s-J)*ceiling(2^(s-J)*k[indices])] <- n[[s]][ ceiling(2^(s-J)*k[indices]) ] - 1
}
}
# STEP 2 etc -------------------------
# compute log lik
#log_px <- + sum(dnorm(x, mean = mu_hat, sd = sd_hat, log = TRUE)) + log_qx
# propose c
c_prop <- exp(rnorm(1, mean = log(c), sd = sqrt(V)))
log_qx_prop <- algo1(J = J, c = c_prop, x = x, mu = mu_hat, sigma = sd_hat)
log_threshold <- (log_qx_prop - log_qx +
dgamma(c_prop, 5,1, log = TRUE) - dgamma(c, 5,1, log = TRUE))
if( log(runif(1)) < log_threshold ){
c <- c_prop
log_qx <- log_qx_prop
}
if (iter > B){
log_px <- N*J*log(2) + sum(dnorm(x, mean = mu_hat, sd = sd_hat, log = TRUE)) + log_qx
SUM <- SUM + exp(log_px)
}
}
# WHAT?
return(list(Ep = SUM/M, last_x = x))
}
censored_permutation_test(t1 = t1, t2 = t2, delta1 = delta1, delta2 = delta2, 10)
readRDS('type1error_MH_rate_0_7.rds')
readr::readRDS('type1error_MH_rate_0_7.rds')
results <- data.frame(me = 'Andrea')
filename <- paste0('type1error_MH_rate_', opt$rate, '.rds')
saveRDS(results,file=filename)
option_list <- list(
make_option("--rate", default = 0.5,
help = 'Experimental Censoring Rate')
)
opt <- parse_args(OptionParser(option_list=option_list))
require(optparse)
option_list <- list(
make_option("--rate", default = 0.5,
help = 'Experimental Censoring Rate')
)
opt <- parse_args(OptionParser(option_list=option_list))
opt$rate <- gsub('\\.', '_', opt$rate)
results <- data.frame(me = 'Andrea')
filename <- paste0('type1error_MH_rate_', opt$rate, '.rds')
saveRDS(results,file=filename)
readRDS(filename)
